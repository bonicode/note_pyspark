{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark Note.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5lytDHjyLVibIylfbFj/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonioloff/note_pyspark/blob/main/PySpark_Note.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation on how Spark works:\n",
        "- https://stackoverflow.com/questions/32621990/what-are-workers-executors-cores-in-spark-standalone-cluster"
      ],
      "metadata": {
        "id": "Dzs68uSOlSTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the pyspark package\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "fUlx7fwBq6ck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684f4d28-fcdc-4add-b4ed-76f732e98f6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 36.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=8f84150baab007bfd1210ae405ccc79e10e52ff52e381376f0595fad7ad7f661\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext"
      ],
      "metadata": {
        "id": "AjzjvFw_q_Qy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jINbbaLZqyyH"
      },
      "outputs": [],
      "source": [
        "# Initialize spark context\n",
        "conf = SparkConf().setMaster(\"local\").setAppName(\"Spark App\")\n",
        "sc = SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resilient Distributed Dataset (RDD) Interface\n",
        "\n",
        "RDD can be used to store all types of data source:\n",
        "- Manual entry\n",
        "- textFile from local file, s3, hdfs, etc.\n",
        "- Hive\n",
        "- JDBC\n",
        "- Cassandra\n",
        "- HBase\n",
        "- ElasticSearch\n",
        "- JSON, etc"
      ],
      "metadata": {
        "id": "zWRlZpNW5yPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual way to create RDD\n",
        "rdd = sc.parallelize([1,2,3,4])"
      ],
      "metadata": {
        "id": "e873UFpLqOiN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RDD from text file\n",
        "rdd = sc.textFile(\"sample_data/california_housing_test.csv\")"
      ],
      "metadata": {
        "id": "chJADF0ZrNmx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first 5 rows\n",
        "rdd.take(5)\n",
        "# rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u6w2BA-up6p",
        "outputId": "966bc0cc-4017-4eb9-c136-59a9a86dc64b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"',\n",
              " '-122.050000,37.370000,27.000000,3885.000000,661.000000,1537.000000,606.000000,6.608500,344700.000000',\n",
              " '-118.300000,34.260000,43.000000,1510.000000,310.000000,809.000000,277.000000,3.599000,176500.000000',\n",
              " '-117.810000,33.780000,27.000000,3589.000000,507.000000,1484.000000,495.000000,5.793400,270500.000000',\n",
              " '-118.360000,33.820000,28.000000,67.000000,15.000000,49.000000,11.000000,6.135900,330000.000000']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flatMap()\n",
        "rdd.flatMap(lambda x: x.split(\",\")).take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m4cqArnyqWs",
        "outputId": "fc6dfbd5-ed18-412d-871d-588abceb3d04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"longitude\"',\n",
              " '\"latitude\"',\n",
              " '\"housing_median_age\"',\n",
              " '\"total_rooms\"',\n",
              " '\"total_bedrooms\"',\n",
              " '\"population\"',\n",
              " '\"households\"',\n",
              " '\"median_income\"',\n",
              " '\"median_house_value\"',\n",
              " '-122.050000']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Operations with RDD\n",
        "These are the basic operations in rdd: \n",
        "- map, \n",
        "- flatmap, \n",
        "- filter, \n",
        "- distinct, \n",
        "- sample, \n",
        "- union, \n",
        "- intersection, \n",
        "- subtract, \n",
        "- cartesian\n",
        "\n",
        "_bykey_:\n",
        "- reduceByKey()\n",
        "- groupByKey()\n",
        "- sortByKey()\n",
        "- keys()\n",
        "- values()"
      ],
      "metadata": {
        "id": "zSJ9l-Gor9rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map()\n",
        "income_vs_homevalue = rdd.map(lambda x: x.split(\",\")).map(lambda x: (x[-2], x[-1]))\n",
        "income_vs_homevalue.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVuuZ0LAr0-s",
        "outputId": "d75672ae-5b88-4991-92ea-46e82c374834"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\"median_income\"', '\"median_house_value\"'),\n",
              " ('6.608500', '344700.000000'),\n",
              " ('3.599000', '176500.000000'),\n",
              " ('5.793400', '270500.000000'),\n",
              " ('6.135900', '330000.000000')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reduceByKey()\n",
        "income_vs_homevalue.reduceByKey(lambda x, y: x + y).take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUIzPmAzzWvk",
        "outputId": "0043e892-a552-48c2-87da-ebe61056157a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\"median_income\"', '\"median_house_value\"'),\n",
              " ('6.608500', '344700.000000'),\n",
              " ('3.599000', '176500.000000'),\n",
              " ('5.793400', '270500.000000'),\n",
              " ('6.135900', '330000.000000106300.000000225000.000000')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keys()\n",
        "income_vs_homevalue.keys().take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bkBZll00ABJ",
        "outputId": "6ff77bf8-5fe8-4297-d608-80dc6da1aa7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"median_income\"', '6.608500', '3.599000', '5.793400', '6.135900']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# values()\n",
        "income_vs_homevalue.values().take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb41-bEM0Hqs",
        "outputId": "53d266d7-a66d-430e-bfb2-36fc8c3caca6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"median_house_value\"',\n",
              " '344700.000000',\n",
              " '176500.000000',\n",
              " '270500.000000',\n",
              " '330000.000000']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sortByKey()\n",
        "income_vs_homevalue.sortByKey().take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umhz9tuE0LX6",
        "outputId": "4427397a-a6d9-48a9-f615-db921298554c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\"median_income\"', '\"median_house_value\"'),\n",
              " ('0.499900', '500001.000000'),\n",
              " ('0.536000', '162500.000000'),\n",
              " ('0.536000', '275000.000000'),\n",
              " ('0.536000', '87500.000000')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SparkSQL: DataFrame (DF) / Datasets"
      ],
      "metadata": {
        "id": "_5INzzJc54WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike RDD, DataFrame has some benefits:\n",
        "- Contains row objects\n",
        "- Can run sql\n",
        "- Can have schema\n",
        "- Can communicate JDBC and ODBC and Tableau\n",
        "\n",
        "Instead using SparkContext, DF lives in SparkSession.\n",
        "\n",
        "__Datasets__ are typed Dataframe, it's used in typed programming language like Scala and Java, but in Python that is untyped we can use DataFrame.\n",
        "\n",
        "Typed means we have to specifically tell what is the data type of the columns.\n"
      ],
      "metadata": {
        "id": "E0Bpcxye6Cob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row, functions as fun"
      ],
      "metadata": {
        "id": "Oio7MqnjujNY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ],
      "metadata": {
        "id": "2i-d5pmQ9SFT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputData = spark.read.csv(\"sample_data/california_housing_test.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "DWSPx4zD9mKH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputData.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO4c2g329no7",
        "outputId": "4e06dcc1-4d16-4c5d-fc87-11cda83ed363"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputData.select(\"longitude\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OUia81k94xZ",
        "outputId": "81b7d7d3-0698-4bac-bbac-4139f739bdbe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|longitude|\n",
            "+---------+\n",
            "|  -122.05|\n",
            "|   -118.3|\n",
            "|  -117.81|\n",
            "|  -118.36|\n",
            "|  -119.67|\n",
            "+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputData.filter(inputData.total_rooms > 1000).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fkL5guZIk5E",
        "outputId": "fba16c64-c708-44d9-92ca-f64a43f32c3a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -122.05|   37.37|              27.0|     3885.0|         661.0|    1537.0|     606.0|       6.6085|          344700.0|\n",
            "|   -118.3|   34.26|              43.0|     1510.0|         310.0|     809.0|     277.0|        3.599|          176500.0|\n",
            "|  -117.81|   33.78|              27.0|     3589.0|         507.0|    1484.0|     495.0|       5.7934|          270500.0|\n",
            "|  -119.67|   36.33|              19.0|     1241.0|         244.0|     850.0|     237.0|       2.9375|           81700.0|\n",
            "|  -119.56|   36.51|              37.0|     1018.0|         213.0|     663.0|     204.0|       1.6635|           67000.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputData.groupBy(\"households\").count().show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqnmy2meI4ea",
        "outputId": "052b859b-31e5-4975-a2fe-d7ddf4512ad4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|households|count|\n",
            "+----------+-----+\n",
            "|     305.0|    4|\n",
            "|     558.0|    2|\n",
            "|     496.0|    1|\n",
            "|     596.0|    5|\n",
            "|     299.0|    4|\n",
            "+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputData.select(inputData.households, inputData.median_income * 0.8).show(3)"
      ],
      "metadata": {
        "id": "IJJoC7FdJTcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7796305a-c5d5-41a3-becc-769836682142"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------------------+\n",
            "|households|(median_income * 0.8)|\n",
            "+----------+---------------------+\n",
            "|     606.0|               5.2868|\n",
            "|     277.0|   2.8792000000000004|\n",
            "|     495.0|    4.634720000000001|\n",
            "+----------+---------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputData.groupBy(\"households\").agg(fun.round(fun.avg(\"median_income\"), 2)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97KusAoYMWIc",
        "outputId": "335e9bf0-4421-40ad-c0bd-07cf4e47ed8f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------------------+\n",
            "|households|round(avg(median_income), 2)|\n",
            "+----------+----------------------------+\n",
            "|     305.0|                        4.49|\n",
            "|     558.0|                         3.4|\n",
            "|     496.0|                        4.23|\n",
            "|     596.0|                        3.08|\n",
            "|     299.0|                        2.89|\n",
            "+----------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text\n",
        "textData = spark.read.text(\"sample_data/README.md\")"
      ],
      "metadata": {
        "id": "QVeVet5hUMab"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split texts into words\n",
        "words = textData.select(fun.explode(fun.split(textData.value, \"\\\\W+\")).alias(\"word\"))"
      ],
      "metadata": {
        "id": "LlL6vPz6XOoN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count words\n",
        "words.groupBy(\"word\").count().sort(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37hjEAbqX30h",
        "outputId": "c0f2a891-5383-42d5-e4d6-eee726dde518"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|         word|count|\n",
            "+-------------+-----+\n",
            "|             |   23|\n",
            "|        https|    4|\n",
            "|           is|    4|\n",
            "|vega_datasets|    3|\n",
            "|          the|    3|\n",
            "|     Anscombe|    3|\n",
            "|          com|    3|\n",
            "|            a|    3|\n",
            "|           en|    2|\n",
            "|         copy|    2|\n",
            "|           in|    2|\n",
            "|         data|    2|\n",
            "|          was|    2|\n",
            "|      housing|    2|\n",
            "|         json|    2|\n",
            "|     anscombe|    2|\n",
            "|          csv|    2|\n",
            "|           of|    2|\n",
            "|         wiki|    2|\n",
            "|          org|    2|\n",
            "+-------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using dataframe to analyze movielens dataset"
      ],
      "metadata": {
        "id": "LSY3CImBl6w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXUaimaVYFqk",
        "outputId": "476dad57-85e7-4189-ce23-b8a5f5e4f5b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 5778k  100 5778k    0     0  17.9M      0 --:--:-- --:--:-- --:--:-- 17.9M\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType, LongType\n",
        "\n",
        "# Prepare rating dataset\n",
        "schema = StructType([StructField(\"UserID\", StringType()),\n",
        "                     StructField(\"MovieID\", StringType()),\n",
        "                     StructField(\"Ratings\", IntegerType()),\n",
        "                     StructField(\"Timestamp\", LongType())])\n",
        "\n",
        "rating = spark.read.csv(\"ml-1m/ratings.dat\", sep=\"::\", schema=schema)\n",
        "\n",
        "# Prepare movie dataset\n",
        "schema = StructType([StructField(\"MovieID\", StringType()),\n",
        "                     StructField(\"Title\", StringType()),\n",
        "                     StructField(\"Genres\", StringType())])\n",
        "\n",
        "movie = spark.read.csv(\"ml-1m/movies.dat\", sep=\"::\", schema=schema)\n"
      ],
      "metadata": {
        "id": "qaJzfUrjmCaR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLiEoHNEplGV",
        "outputId": "d970ed85-51e0-4e24-dc5c-f69fccbb120a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-------+---------+\n",
            "|UserID|MovieID|Ratings|Timestamp|\n",
            "+------+-------+-------+---------+\n",
            "|     1|   1193|      5|978300760|\n",
            "|     1|    661|      3|978302109|\n",
            "|     1|    914|      3|978301968|\n",
            "|     1|   3408|      4|978300275|\n",
            "+------+-------+-------+---------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqFjN9fxJz6h",
        "outputId": "e1a8d4d9-2f00-4339-e4a2-1fadbc7d5295"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------------------------+----------------------------+\n",
            "|MovieID|Title                             |Genres                      |\n",
            "+-------+----------------------------------+----------------------------+\n",
            "|1      |Toy Story (1995)                  |Animation|Children's|Comedy |\n",
            "|2      |Jumanji (1995)                    |Adventure|Children's|Fantasy|\n",
            "|3      |Grumpier Old Men (1995)           |Comedy|Romance              |\n",
            "|4      |Waiting to Exhale (1995)          |Comedy|Drama                |\n",
            "|5      |Father of the Bride Part II (1995)|Comedy                      |\n",
            "+-------+----------------------------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_rated = rating.groupBy(\"MovieID\").count().sort(\"count\", ascending=False)\n",
        "top_rated.show(5)"
      ],
      "metadata": {
        "id": "xGrxorDCmpMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bd3679-4aa1-4e72-8b75-41dde877eb33"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|MovieID|count|\n",
            "+-------+-----+\n",
            "|   2858| 3428|\n",
            "|    260| 2991|\n",
            "|   1196| 2990|\n",
            "|   1210| 2883|\n",
            "|    480| 2672|\n",
            "+-------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To sent data to all executer and be available to all executer anytime, we can use sc.broadcast()\n",
        "\n",
        "By doing this, the executors will have exactly the same variable values."
      ],
      "metadata": {
        "id": "OuoQqFtaL00_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TCVOoBLDI_FO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}